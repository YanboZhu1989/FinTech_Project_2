{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from prophet import Prophet\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from ANOTHER MACHINE LEARNING LIBRARY import SOMETHING ELSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a2c6a-e82b-4101-80d1-63b4d9ac25db",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d762d47-7301-4d90-a0a9-377a3325a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIs\n",
    "# Use Alpaca for BTC data\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "load_dotenv()\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bb037-f094-4a53-af91-0f0db401edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Alpaca API object\n",
    "api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version = \"v2\"\n",
    ")\n",
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf209ca5-56e7-4c78-8dac-3daf8af32588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data Files\n",
    "start_date = pd.Timestamp(\"2013-07-03\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2023-07-03\", tz=\"America/New_York\").isoformat()\n",
    "tickers = ['BTC']\n",
    "timeframe = \"1Day\"\n",
    "df_stock = api.get_bars(\n",
    "        tickers,\n",
    "        timeframe,\n",
    "        start=start_date,\n",
    "        end=end_date\n",
    "    ).df\n",
    "df_stock.hea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa26cbd-ad21-444d-a33f-1b1ecbcd80b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ed471a-bb25-4a03-8e93-e69388f32bdb",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e25cf-4d18-4a03-8442-5f702a841afc",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f447658-6938-4217-919a-23fab38f11d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737e2f5-dc65-4e4c-8f63-c9372f01cc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88303567-893c-4858-99fc-6d7c612358ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a4949b-8223-4cc8-a56d-11fce3a8116e",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b1848-8d2d-4ba0-825d-0d8aa056ffa3",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8623bc-dd3a-4e43-9128-4f0967d8199c",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8706be-2e18-4a6e-b976-d487f7524da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the Prophet function, store as an object\n",
    "pr_model = Prophet()\n",
    "\n",
    "# Fit the Prophet model.\n",
    "model.fit(df)\n",
    "\n",
    "# Create a future dataframe to hold predictions\n",
    "# Make the prediction go out as far as 1000 hours (approx 40 days)\n",
    "pr_future_trends = model.make_future_dataframe(periods=1000, freq=\"H\")\n",
    "\n",
    "# View the last five rows of the predictions\n",
    "pr_future_trends.tail()\n",
    "\n",
    "# Make the predictions for the trend data using the future_trends DataFrame\n",
    "pr_forecast_trends = model.predict(pr_future_trends)\n",
    "\n",
    "# Display the first five rows of the forecast DataFrame\n",
    "pr_forecast_trends.head()\n",
    "\n",
    "# Plot the Prophet predictions for the Mercado trends data\n",
    "pr_model.plot(pr_forecast_trends)\n",
    "\n",
    "# Use the plot_components function to visualize the forecast results \n",
    "pr_figures = model.plot_components(pr_forecast_trends)\n",
    "\n",
    "\n",
    "# At this point, it's useful to set the `datetime` index of the forecast data.\n",
    "pr_forecast_trends = pr_forecast_trends.set_index([\"ds\"])\n",
    "pr_forecast_trends.head()\n",
    "\n",
    "# From the `forecast_trends` DataFrame, use hvPlot to visualize\n",
    "#  the yhat, yhat_lower, and yhat_upper columns over the last 10 days (24*10 = 240) \n",
    "pr_forecast_trends[[\"yhat\", \"yhat_lower\", \"yhat_upper\"]].iloc[-240:, :].hvplot()\n",
    "\n",
    "# Create a `forecast_march_2021` Dataframe, which contains just forecasts for that month\n",
    "# The DataFrame should include the columns yhat_upper, yhat_lower, and yhat\n",
    "pr_forecast_march_2021 = pr_forecast_trends.loc[\"2021-03-01\":\"2021-03-31\"][[\"yhat_upper\", \"yhat_lower\", \"yhat\"]]\n",
    "\n",
    "# Replace the column names to something less technical sounding\n",
    "pr_forecast_march_2021 = pr_forecast_march_2021.rename(\n",
    "    columns={\n",
    "        \"yhat_upper\": \"Best Case\",\n",
    "        \"yhat_lower\": \"Worst Case\", \n",
    "        \"yhat\": \"Most Likely Case\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Review the last five rows of the DataFrame\n",
    "pr_forecast_march_2021.tail()\n",
    "\n",
    "# Display the average forecasted price for March 2021\n",
    "forecast_march_2021.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c8365-ff25-49f5-8ce9-20ff67f648d7",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32106bf8-aa53-41ec-9947-73f8037c6ac9",
   "metadata": {},
   "source": [
    "## Neural Networks - Tensorflow, Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d75db2-b3f0-4e9d-a2c0-8c722afcba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X.columns)\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features\n",
    "\n",
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 =  8\n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 =  4\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons, activation='relu'))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb04e08-5f52-4fab-abd2-f856d5348fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae30f2-ecac-4be4-9198-7fa6582cc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "num_epochs = 50\n",
    "model_1 = nn.fit(X_train_scaled, y_train, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb30add-b234-462f-995d-040d1d8f96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d7603-3e68-440b-8f5b-e1b1a7417ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path\n",
    "file_path = Path('Resources/AlphabetSoup.h5')\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66210334-81ed-4334-85a2-fd477759f657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d97542-c599-420e-b0be-7be920615e9b",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce4549-c7b5-4205-87bb-375d3413468a",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8feb4-f1af-46ac-a0b9-5365e6fefcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(applicant_data_df.dtypes[applicant_data_df.dtypes == \"object\"].index)\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e0601-f840-42a2-b97a-5a3dc1d3741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c82ad-99eb-49ed-9161-4606f9d3e668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c297d2-de72-4cc7-bcfa-351c4733efee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a3b83-f8ec-41b9-9854-ab01730f69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642acd65-6430-471e-a696-56ab837eb7df",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87205ca4-e7dd-4dec-96a7-81b4bb5aa2fb",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6701751-5088-4caf-8006-6ddd5e3220f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "lr_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72d6b3-439a-4c43-a256-5be571ce08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "lr_predictions = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5a2e7-3479-43e8-b1b8-c6ffe9a61a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf8163-5f4b-4b4f-8130-362489b4c08e",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32872a-7cf8-43d6-9815-09ec3c161a77",
   "metadata": {},
   "source": [
    "### Algo trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3a020-500a-4c4a-83b4-ae6eb235d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "trading_df[\"actual_returns\"] = trading_df[\"close\"].pct_change()\n",
    "\n",
    "# Display sample data\n",
    "trading_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbfb6c-f071-4acf-b231-d746e9b5d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN values from the DataFrame\n",
    "trading_df = trading_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62717a66-a206-4a23-96bc-c2c2342d17a9",
   "metadata": {},
   "source": [
    "#### Generating the Features and Target Sets\n",
    "\n",
    "##### Creating the Features Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8b1fb-a3ac-409f-92e9-ff500e74a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window size of 4\n",
    "short_window = 4\n",
    "\n",
    "# Create an SMA that uses short_window, and assign it to a new column named “sma_fast”\n",
    "trading_df[\"sma_fast\"] = trading_df[\"close\"].rolling(window=short_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196bf3d-f1ba-456e-a1ce-d0ea958057dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window size of 20\n",
    "long_window = 20\n",
    "\n",
    "# Create an SMA that uses long_window, and assign it to a new columns named “sma_slow”\n",
    "trading_df[\"sma_slow\"] = trading_df[\"close\"].rolling(window=long_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eeae0-7907-4ad4-ad13-10ace92211ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaNs using dropna()\n",
    "trading_df = trading_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeebe4e-d129-431e-bd59-7156c3afac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the `sma_fast` and `sma_slow` columns to a new DataFrame called `X`\n",
    "X = trading_df[[\"sma_fast\", \"sma_slow\"]].shift().dropna().copy()\n",
    "\n",
    "# Display sample data\n",
    "display(X.head())\n",
    "display(X.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b9b9c-af3e-484e-8322-30fac1f1993e",
   "metadata": {},
   "source": [
    "##### Creating the Target Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce0bc2-a281-4536-8084-b0752ce6b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the `trading_df` called \"signal\" setting its value to zero.\n",
    "trading_df[\"signal\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e22f67-5a92-45d9-a04b-b4d42f8395e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the signal to buy\n",
    "trading_df.loc[(trading_df[\"actual_returns\"] >= 0), \"signal\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e909564-ab26-4ae9-af29-6680bffe58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the signal to sell\n",
    "trading_df.loc[(trading_df[\"actual_returns\"] < 0), \"signal\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d79ceb-b4e1-4a10-b822-53fe7c41a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the new \"signal\" column to a new Series called `y`.\n",
    "y = trading_df[\"signal\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01343a09-9d14-4054-98d1-e679a6c00d34",
   "metadata": {},
   "source": [
    "#### Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b6e66-1121-4017-86d5-5d2e4e8e4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b5e63-ea51-49ed-a11e-e09b4a1955aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38398334-f04d-4cf7-b0de-c9574b01df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 18 months\n",
    "training_end = X.index.min() + DateOffset(months=18)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c2cae-219b-4173-a8f0-a7b1bfed07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef69f8a-8342-4b7c-b0f8-2162891bc347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de84e96-eecc-4012-9b85-c0339bd8593c",
   "metadata": {},
   "source": [
    "#### Standardize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d83ff-833f-4e34-94f2-599a8c6c602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a472b40-ddd3-4ca3-a27a-9045beafa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    " \n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccd61c-f332-4c09-a344-84608083759e",
   "metadata": {},
   "source": [
    "##### Using Machine Learning Into a Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe201c0e-e3ee-4c98-b28e-0da6a83293bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SVM model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4e0ff-d47a-454e-8063-cb0b6e0c1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier model\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Display the sample predictions\n",
    "training_signal_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a04c0f-6a12-498c-8910-2081697da7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a classification report\n",
    "training_report = classification_report(y_train, training_signal_predictions)\n",
    "\n",
    "# Display report\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca21d1a-e202-48c3-bd4d-1a3dffae78fc",
   "metadata": {},
   "source": [
    "##### Backtesting a Machine Learning Trading Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebc611-66e2-4fd0-8086-33209a48474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b2b02-a2fd-42e6-bf26-c6d69e4f2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994891e-0702-4f4f-8efe-cff859ba0e3f",
   "metadata": {},
   "source": [
    "##### Visually Compare the Actual and Predicted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ae2f8-ee2d-44d4-bb83-bcd6bb853e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "predictions_df[\"predicted_signal\"] = testing_signal_predictions\n",
    "\n",
    "predictions_df[\"actual_returns\"] = trading_df[\"actual_returns\"]\n",
    "\n",
    "predictions_df[\"trading_algorithm_returns\"] = (\n",
    "    predictions_df[\"actual_returns\"] * predictions_df[\"predicted_signal\"]\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2ad29-49ca-459e-8da5-ae7a3d031309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bb428-e72c-47ff-9ddb-38ca5c68d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779f369-1b8d-46e2-8733-3089a6fcef35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6335629-f87f-419f-b100-c7d8dbd5c308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc72355-5af9-4a41-a237-62b6ba5ba7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8726efff-a22e-4b46-b237-76aef8b9f60e",
   "metadata": {},
   "source": [
    "# Save each of your alternative models as an HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28edc9-1042-4b19-b625-e84c05efc76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed81083-0cdc-4644-b7e4-42ea83c6961d",
   "metadata": {},
   "source": [
    "# Output\n",
    "## Connect to an External Exchange (Demo Account)\n",
    "or\n",
    "## Send an SMS (Backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebd3fa-b4a7-4749-97c6-3fd2f98a554c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d5ffec-1f7b-4445-872b-d6135f1ae29e",
   "metadata": {},
   "source": [
    "# Nice to have: Sentiment Analysis APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd67509-df67-46dc-b7d1-06fcd660ddac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
